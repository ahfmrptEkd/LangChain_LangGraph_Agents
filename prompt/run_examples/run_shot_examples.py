"""
Shot ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‚¬ìš© ì˜ˆì œ

`templates.py`ì— ì •ì˜ëœ ì •ì /ë™ì  Few-shot í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜ë“¤ì„
ì‚¬ìš©í•˜ì—¬ LLM ì²´ì¸ì„ êµ¬ì„±í•˜ê³  ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.
"""

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from rich.console import Console
from rich.panel import Panel

from ..templates import create_static_few_shot_template, create_dynamic_few_shot_template

load_dotenv()
console = Console()


def run_static_few_shot_example(llm):
    """
    ì •ì  Few-shot í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì˜ˆì œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    console.print(Panel.fit("ğŸ”¹ 1. ì •ì  Few-shot í”„ë¡¬í”„íŠ¸ ì˜ˆì œ", style="green"))

    # 1. Few-shot ì˜ˆì œ ë°ì´í„°
    examples = [
        {"input": "ì´ ì˜í™”ëŠ” ì •ë§ í™˜ìƒì ì´ì—ˆì–´ìš”!", "output": "ê¸ì •"},
        {"input": "ìŒì‹ì´ ë„ˆë¬´ ì°¨ê°‘ê³  ë§›ì´ ì—†ì–´ìš”.", "output": "ë¶€ì •"},
        {"input": "ê·¸ëƒ¥ í‰ë²”í•œ í•˜ë£¨ì˜€ì–´ìš”.", "output": "ì¤‘ë¦½"},
    ]

    # 2. í…œí”Œë¦¿ ìƒì„±
    static_prompt = create_static_few_shot_template(
        examples=examples,
        system_prefix="ë‹¤ìŒì€ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ë¶„ì„í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤. 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ë¡œ ë‹µí•´ì£¼ì„¸ìš”.",
        human_suffix="í…ìŠ¤íŠ¸: {text}"
    )

    # 3. ì²´ì¸ ìƒì„± ë° ì‹¤í–‰
    chain = static_prompt | llm
    text = "ë°°ì†¡ì´ ë¹ ë¥´ê³  ì œí’ˆ í’ˆì§ˆë„ ë§Œì¡±ìŠ¤ëŸ¬ì›Œìš”."
    console.print(f"ğŸ“ ë¶„ì„í•  í…ìŠ¤íŠ¸: {text}")

    try:
        response = chain.invoke({"text": text})
        console.print(f"ğŸ¤– ê°ì • ë¶„ì„ ê²°ê³¼: {response.content}")
    except Exception as e:
        console.print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

    console.print("-" * 50)


def run_dynamic_few_shot_example(llm):
    """
    ë™ì (ì˜ë¯¸ ê¸°ë°˜) Few-shot í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì˜ˆì œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    console.print(Panel.fit("ğŸ”¹ 2. ë™ì  Few-shot í”„ë¡¬í”„íŠ¸ ì˜ˆì œ", style="magenta"))

    # 1. ì „ì²´ ì˜ˆì œ í’€
    examples = [
        {"question": "íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë²•?", "answer": "`sorted()` í•¨ìˆ˜ë‚˜ `list.sort()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."},
        {"question": "SQLì—ì„œ ì¤‘ë³µì„ ì œê±°í•˜ëŠ” ë²•?", "answer": "`SELECT DISTINCT` êµ¬ë¬¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."},
        {"question": "Reactì—ì„œ ìƒíƒœë¥¼ ì–´ë–»ê²Œ ê´€ë¦¬í•˜ë‚˜ìš”?", "answer": "`useState` ë˜ëŠ” `useReducer` í›…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."},
        {"question": "íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ì—ì„œ í‚¤ë¥¼ í™•ì¸í•˜ëŠ” ë²•?", "answer": "`'key' in my_dict` êµ¬ë¬¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."},
    ]

    # 2. í…œí”Œë¦¿ ìƒì„±
    try:
        dynamic_prompt = create_dynamic_few_shot_template(
            examples=examples,
            system_prefix="ë‹¤ìŒì€ í”„ë¡œê·¸ë˜ë° ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ì˜ˆì‹œì…ë‹ˆë‹¤. ìœ ì‚¬í•œ ì§ˆë¬¸ì— ëŒ€í•´ ë‹µë³€í•´ì£¼ì„¸ìš”.",
            human_suffix="{question}",
            k=2
        )
    except Exception as e:
        console.print(f"âŒ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
        console.print("ğŸ’¡ FAISS ë“± í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return

    # 3. ì²´ì¸ ìƒì„± ë° ì‹¤í–‰
    chain = dynamic_prompt | llm
    question = "íŒŒì´ì¬ì—ì„œ ë”•ì…”ë„ˆë¦¬ì˜ ê°’ì„ ê°€ì ¸ì˜¤ëŠ” ë°©ë²•ì€?"
    console.print(f"ğŸ“ ì§ˆë¬¸: {question}")

    try:
        response = chain.invoke({"question": question})
        console.print(f"ğŸ¤– AI ì‘ë‹µ:\n{response.content}")
    except Exception as e:
        console.print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

    console.print("-" * 50)


def main():
    """
    ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
    """
    if not os.getenv("OPENAI_API_KEY"):
        console.print("âŒ OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    console.print(Panel.fit("ğŸš€ Shot ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ì˜ˆì œ ì‹¤í–‰", style="bold green"))
    
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.3)

    run_static_few_shot_example(llm)
    run_dynamic_few_shot_example(llm)

    console.print(Panel.fit("âœ… ëª¨ë“  Shot ê¸°ë°˜ ì˜ˆì œ ì‹¤í–‰ ì™„ë£Œ", style="bold green"))


if __name__ == "__main__":
    main()
