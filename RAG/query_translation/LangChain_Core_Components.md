# LangChain Core Components Guide

## Overview
Query Translationê³¼ RAG êµ¬í˜„ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” LangChainì˜ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë“¤ì— ëŒ€í•œ ì¢…í•© ê°€ì´ë“œì…ë‹ˆë‹¤. ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œì™€ í•¨ê»˜ ê° ì»´í¬ë„ŒíŠ¸ì˜ ì—­í• ê³¼ í™œìš©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.

## ğŸ”„ Document Serialization: `dumps` & `loads`

### ê¸°ë³¸ ê°œë…
Document ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜(ì§ë ¬í™”)í•˜ê³  ë‹¤ì‹œ ë³µì›(ì—­ì§ë ¬í™”)í•˜ëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.

```python
from langchain.load import dumps, loads
from langchain.schema import Document

# Document ê°ì²´ ìƒì„±
doc = Document(
    page_content="This is the content of the document", 
    metadata={"source": "web", "page": 1}
)

# dumps: Document â†’ ë¬¸ìì—´
serialized = dumps(doc)
print(type(serialized))  # <class 'str'>

# loads: ë¬¸ìì—´ â†’ Document  
restored_doc = loads(serialized)
print(type(restored_doc))  # <class 'langchain.schema.Document'>
print(restored_doc.page_content)  # "This is the content of the document"
```

### Multi-Query RAGì—ì„œì˜ í™œìš©

#### ì¤‘ë³µ ì œê±° ê³¼ì •
```python
def get_unique_union(documents: list[list]):
    """
    ì—¬ëŸ¬ ì¿¼ë¦¬ ê²°ê³¼ì—ì„œ ì¤‘ë³µ ë¬¸ì„œ ì œê±°
    
    Input: [
        [Doc1, Doc2, Doc3],  # Query 1 ê²°ê³¼
        [Doc2, Doc4, Doc5],  # Query 2 ê²°ê³¼  
        [Doc1, Doc3, Doc6],  # Query 3 ê²°ê³¼
    ]
    Output: [Doc1, Doc2, Doc3, Doc4, Doc5, Doc6]  # ì¤‘ë³µ ì œê±°ë¨
    """
    
    # 1. ëª¨ë“  Documentë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜ (ë¹„êµ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ê¸°)
    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]
    
    # 2. set()ìœ¼ë¡œ ì¤‘ë³µ ì œê±° (ë¬¸ìì—´ì´ë¯€ë¡œ ë¹„êµ ê°€ëŠ¥)
    unique_docs = list(set(flattened_docs))
    
    # 3. ë‹¤ì‹œ Document ê°ì²´ë¡œ ë³€í™˜
    return [loads(doc) for doc in unique_docs]
```

#### ì™œ ì´ë ‡ê²Œ ë³µì¡í•˜ê²Œ?
```python
# âŒ Document ê°ì²´ ì§ì ‘ ë¹„êµëŠ” ë¶ˆê°€ëŠ¥
doc1 = Document(page_content="Same content", metadata={"source": "web"})
doc2 = Document(page_content="Same content", metadata={"source": "web"})
print(doc1 == doc2)  # False! (ê°ì²´ ì°¸ì¡°ê°€ ë‹¤ë¦„)

# âœ… dumpsë¡œ ë¬¸ìì—´ ë³€í™˜ í›„ ë¹„êµ ê°€ëŠ¥
str1 = dumps(doc1)
str2 = dumps(doc2)
print(str1 == str2)  # True! (ë‚´ìš©ì´ ê°™ìœ¼ë©´ ê°™ì€ ë¬¸ìì—´)
```

### ì£¼ìš” ì‚¬ìš© ì‚¬ë¡€
- **ì¤‘ë³µ ì œê±°**: Multi-Query RAGì—ì„œ ë™ì¼í•œ ë¬¸ì„œ ì œê±°
- **ì €ì¥/ë¡œë“œ**: ë¬¸ì„œë¥¼ íŒŒì¼ì´ë‚˜ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
- **ë„¤íŠ¸ì›Œí¬ ì „ì†¡**: APIë¥¼ í†µí•´ ë¬¸ì„œ ë°ì´í„° ì „ì†¡
- **ìºì‹±**: ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìºì‹œë¡œ ì €ì¥

## ğŸ”— Data Passing: `RunnablePassthrough`

### ê¸°ë³¸ ê°œë…
ì…ë ¥ ë°ì´í„°ë¥¼ ë³€ê²½í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ì¶œë ¥ìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ì…ë‹ˆë‹¤.

```python
from langchain_core.runnables import RunnablePassthrough

# ê¸°ë³¸ ì‚¬ìš©ë²•
passthrough = RunnablePassthrough()
result = passthrough.invoke("Hello World")
print(result)  # "Hello World" (ê·¸ëŒ€ë¡œ ì¶œë ¥)

# íŒŒì´í”„ë¼ì¸ì—ì„œ ì‚¬ìš©
chain = (
    {"input": RunnablePassthrough(), "processed": some_processor}
    | next_step
)
```

### RAG íŒŒì´í”„ë¼ì¸ì—ì„œì˜ í™œìš©

#### ë‹¨ìˆœí•œ RAG ì²´ì¸
```python
# ë¬¸ìì—´ì„ ì§ì ‘ ì „ë‹¬í•˜ëŠ” êµ¬ì¡°
simple_rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# ì‚¬ìš© ì‹œ
result = simple_rag_chain.invoke("What is task decomposition?")
```

#### ë‚´ë¶€ ë™ì‘ ê³¼ì •
```python
# 1. ì…ë ¥: "What is task decomposition?"

# 2. ë”•ì…”ë„ˆë¦¬ êµ¬ì„±:
{
    "context": retriever | format_docs,  # ìë™ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰+í¬ë§·íŒ…
    "question": RunnablePassthrough()    # ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬
}

# 3. ì‹¤ì œ ì‹¤í–‰ ì‹œ:
{
    "context": "retrieved and formatted documents...",
    "question": "What is task decomposition?"  # ê·¸ëŒ€ë¡œ ì „ë‹¬ë¨
}

# 4. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì— ì „ë‹¬
```

### ì œí•œì‚¬í•­ê³¼ ëŒ€ì•ˆ

#### âŒ ë³µì¡í•œ ë”•ì…”ë„ˆë¦¬ êµ¬ì¡°ì—ì„œëŠ” ì‚¬ìš© ë¶ˆê°€
```python
# Multi-Query RAGì—ì„œ ë¬¸ì œ ë°œìƒ
final_rag_chain = (
    {"context": retrieval_chain, "question": RunnablePassthrough()}
    | prompt | llm | StrOutputParser()
)

# í˜¸ì¶œ ì‹œ
result = final_rag_chain.invoke({"question": "What is task decomposition?"})

# ë¬¸ì œ: RunnablePassthroughê°€ ì „ì²´ ë”•ì…”ë„ˆë¦¬ë¥¼ ì „ë‹¬
# í”„ë¡¬í”„íŠ¸: "Question: {'question': 'What is task decomposition?'}" âŒ
```

#### âœ… itemgetter ì‚¬ìš©
```python
from operator import itemgetter

final_rag_chain = (
    {"context": retrieval_chain, "question": itemgetter("question")}
    | prompt | llm | StrOutputParser()
)

# ì˜¬ë°”ë¥¸ ê²°ê³¼
# í”„ë¡¬í”„íŠ¸: "Question: What is task decomposition?" âœ…
```

### ì‹¤ì œ ìƒì„±ë˜ëŠ” í”„ë¡¬í”„íŠ¸ êµ¬ì¡°
```
System: You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:

# ë”•ì…”ë„ˆë¦¬ì—ì„œ ì‚¬ìš©
data = {"question": "What is AI?", "context": "AI is..."}
getter = itemgetter("question")
result = getter(data)  # "What is AI?"

# ë¦¬ìŠ¤íŠ¸ì—ì„œ ì‚¬ìš©
my_list = ["a", "b", "c", "d"]
list_getter = itemgetter(0, 2)
result = list_getter(my_list)  # ("a", "c")

# ì—¬ëŸ¬ í‚¤ ë™ì‹œ ì¶”ì¶œ
multi_getter = itemgetter("question", "context")
result = multi_getter(data)  # ("What is AI?", "AI is...")
```

### vs dict.get() ë¹„êµ

| ê¸°ëŠ¥ | itemgetter | dict.get() |
|------|------------|------------|
| **ê¸°ë³¸ ì¶”ì¶œ** | âœ… `itemgetter("key")(data)` | âœ… `data.get("key")` |
| **ì¡´ì¬í•˜ì§€ ì•ŠëŠ” í‚¤** | âŒ KeyError ë°œìƒ | âœ… None ë°˜í™˜ (ê¸°ë³¸ê°’ ê°€ëŠ¥) |
| **ì—¬ëŸ¬ í‚¤ ë™ì‹œ ì¶”ì¶œ** | âœ… `itemgetter("a", "b")` | âŒ ë¶ˆê°€ëŠ¥ |
| **ë‹¤ì–‘í•œ ë°ì´í„° íƒ€ì…** | âœ… ë”•ì…”ë„ˆë¦¬, ë¦¬ìŠ¤íŠ¸, íŠœí”Œ | âŒ ë”•ì…”ë„ˆë¦¬ë§Œ |
| **íŒŒì´í”„ë¼ì¸ ì‚¬ìš©** | âœ… ì§ì ‘ ì‚¬ìš© ê°€ëŠ¥ | âŒ lambdaë¡œ ê°ì‹¸ì•¼ í•¨ |
| **ì„±ëŠ¥** | ì•½ê°„ ëŠë¦¼ | ì•½ê°„ ë¹ ë¦„ |

### LangChainì—ì„œ ì„ í˜¸í•˜ëŠ” ì´ìœ 

#### íŒŒì´í”„ë¼ì¸ í˜¸í™˜ì„±
```python
# âœ… itemgetter (ê¶Œì¥)
chain = (
    {"context": retrieval_chain, "question": itemgetter("question")}
    | prompt | llm
)

# ğŸ”„ .get() (ê°€ëŠ¥í•˜ì§€ë§Œ ë²ˆê±°ë¡œì›€)
chain = (
    {"context": retrieval_chain, "question": lambda x: x.get("question")}
    | prompt | llm
)
```

## ğŸ“Š Component Comparison Table

| ì»´í¬ë„ŒíŠ¸ | ì£¼ìš” ê¸°ëŠ¥ | ì…ë ¥ íƒ€ì… | ì¶œë ¥ íƒ€ì… | ì£¼ìš” ì‚¬ìš©ì²˜ |
|----------|-----------|-----------|-----------|-------------|
| **dumps** | Document â†’ ë¬¸ìì—´ | Document | str | ì¤‘ë³µ ì œê±°, ì €ì¥ |
| **loads** | ë¬¸ìì—´ â†’ Document | str | Document | ë³µì›, ë¡œë”© |
| **RunnablePassthrough** | ë°ì´í„° ê·¸ëŒ€ë¡œ ì „ë‹¬ | Any | Same | ë‹¨ìˆœ íŒŒì´í”„ë¼ì¸ |
| **itemgetter** | í‚¤/ì¸ë±ìŠ¤ë¡œ ê°’ ì¶”ì¶œ | dict/list/tuple | Any | ë³µì¡í•œ íŒŒì´í”„ë¼ì¸ |

## ğŸ¯ Few-Shot Prompting: `FewShotChatMessagePromptTemplate`

### ê¸°ë³¸ ê°œë…
Few-Shot Promptingì€ AI ëª¨ë¸ì—ê²Œ ì›í•˜ëŠ” ì¶œë ¥ í˜•íƒœë¥¼ ëª‡ ê°œì˜ ì˜ˆì‹œë¡œ ë³´ì—¬ì£¼ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤. LangChainì—ì„œëŠ” `FewShotChatMessagePromptTemplate`ì„ ì‚¬ìš©í•´ ì²´ê³„ì ìœ¼ë¡œ êµ¬í˜„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### êµ¬ì¡° ì´í•´

#### 1. ê¸°ë³¸ êµ¬ì„± ìš”ì†Œ
```python
from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate

# 1. ê°œë³„ ì˜ˆì‹œ í…œí”Œë¦¿ ì •ì˜
example_prompt = ChatPromptTemplate.from_messages([
    ("human", "{input}"),
    ("ai", "{output}"),
])

# 2. ì˜ˆì‹œ ë°ì´í„° ì¤€ë¹„
examples = [
    {"input": "ì§ˆë¬¸1", "output": "ë‹µë³€1"},
    {"input": "ì§ˆë¬¸2", "output": "ë‹µë³€2"},
]

# 3. Few-Shot í…œí”Œë¦¿ ìƒì„±
few_shot_prompt = FewShotChatMessagePromptTemplate(
    example_prompt=example_prompt,
    examples=examples,
)
```

#### 2. Step-back Prompting ì‹¤ì œ ì˜ˆì‹œ
```python
# ì˜ˆì‹œ ë°ì´í„°: êµ¬ì²´ì  ì§ˆë¬¸ â†’ ì¼ë°˜ì  ì§ˆë¬¸
examples = [
    {
        "input": "Could the members of The Police perform lawful arrests?",
        "output": "what can the members of The Police do?",
    },
    {
        "input": "Jan Sindel's was born in what country?",
        "output": "what is Jan Sindel's personal history?",
    },
]

# ê°œë³„ ì˜ˆì‹œ í…œí”Œë¦¿
example_prompt = ChatPromptTemplate.from_messages([
    ("human", "{input}"),
    ("ai", "{output}"),
])

# Few-Shot í…œí”Œë¦¿ ìƒì„±
few_shot_prompt = FewShotChatMessagePromptTemplate(
    example_prompt=example_prompt,
    examples=examples,
)

# ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
final_prompt = ChatPromptTemplate.from_messages([
    ("system", "You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:"),
    few_shot_prompt,  # ì˜ˆì‹œë“¤ì´ ì—¬ê¸°ì— ì‚½ì…ë¨
    ("user", "{question}"),
])
```

## ğŸ¯ ì‹¤ì „ í™œìš© ê°€ì´ë“œ

### When to Use Each Component

#### `dumps` & `loads`
```python
# âœ… ì‚¬ìš©í•˜ëŠ” ê²½ìš°
- Multi-Query RAGì—ì„œ ì¤‘ë³µ ë¬¸ì„œ ì œê±°
- ë¬¸ì„œë¥¼ íŒŒì¼ì´ë‚˜ DBì— ì €ì¥/ë¡œë“œ
- APIë¥¼ í†µí•œ ë¬¸ì„œ ë°ì´í„° ì „ì†¡
- ê²€ìƒ‰ ê²°ê³¼ ìºì‹±

# âŒ ë¶ˆí•„ìš”í•œ ê²½ìš°  
- ë‹¨ìˆœí•œ RAGì—ì„œ ë¬¸ì„œ ì²˜ë¦¬
- ì‹¤ì‹œê°„ ì²˜ë¦¬ë§Œ í•˜ëŠ” ê²½ìš°
```

#### `RunnablePassthrough`
```python
# âœ… ì‚¬ìš©í•˜ëŠ” ê²½ìš°
simple_chain = (
    {"input": RunnablePassthrough(), "processed": processor}
    | prompt | llm
)
simple_chain.invoke("ì§ì ‘ ë¬¸ìì—´ ì „ë‹¬")

# âŒ ì‚¬ìš©í•˜ë©´ ì•ˆ ë˜ëŠ” ê²½ìš°
complex_chain = (
    {"context": retrieval_chain, "question": RunnablePassthrough()}
    | prompt | llm
)
complex_chain.invoke({"question": "ë”•ì…”ë„ˆë¦¬ ì „ë‹¬"})  # ë¬¸ì œ ë°œìƒ!
```

#### `itemgetter`
```python
# âœ… ì‚¬ìš©í•˜ëŠ” ê²½ìš°
- ë”•ì…”ë„ˆë¦¬ ê¸°ë°˜ íŒŒì´í”„ë¼ì¸
- ì—¬ëŸ¬ ê°’ì„ ë™ì‹œì— ì¶”ì¶œí•´ì•¼ í•  ë•Œ
- LangChain í‘œì¤€ íŒ¨í„´ ë”°ë¥¼ ë•Œ

# ğŸ”„ ëŒ€ì•ˆ (.get())
- ì—ëŸ¬ ì•ˆì „ì„±ì´ í•„ìš”í•  ë•Œ
- ê¸°ë³¸ê°’ì´ í•„ìš”í•  ë•Œ
```

## ğŸ“ Best Practices

### 1. **Multi-Query RAG Pattern**
```python
def get_unique_union(documents: list[list]):
    # dumps/loadsë¡œ ì¤‘ë³µ ì œê±°
    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]
    unique_docs = list(set(flattened_docs))
    return [loads(doc) for doc in unique_docs]

final_rag_chain = (
    {"context": retrieval_chain | format_docs, 
     "question": itemgetter("question")}  # itemgetter ì‚¬ìš©
    | prompt | llm | StrOutputParser()
)
```

### 2. **Simple RAG Pattern**
```python
simple_rag_chain = (
    {"context": retriever | format_docs, 
     "question": RunnablePassthrough()}  # RunnablePassthrough ì‚¬ìš©
    | prompt | llm | StrOutputParser()
)
```

### 3. **Error-Safe Pattern**
```python
# ì—ëŸ¬ ì•ˆì „ì„±ì´ ì¤‘ìš”í•œ ê²½ìš°
safe_chain = (
    {"context": retrieval_chain | format_docs,
     "question": lambda x: x.get("question", "ê¸°ë³¸ ì§ˆë¬¸")}
    | prompt | llm | StrOutputParser()
)
```

## ğŸ” Debugging Tips

### Document Serialization Issues
```python
# ë¬¸ì œ: Document ë¹„êµê°€ ì•ˆ ë¨
if doc1 == doc2:  # âŒ í•­ìƒ False
    print("ê°™ì€ ë¬¸ì„œ")

# í•´ê²°: dumpsë¡œ ë¹„êµ
if dumps(doc1) == dumps(doc2):  # âœ… ë‚´ìš© ë¹„êµ
    print("ê°™ì€ ë¬¸ì„œ")
```

### Pipeline Data Flow Issues
```python
# ë¬¸ì œ: ë”•ì…”ë„ˆë¦¬ ì „ì²´ê°€ ì „ë‹¬ë¨
{"question": RunnablePassthrough()}
# ê²°ê³¼: {"question": {"question": "actual question"}}

# í•´ê²°: itemgetterë¡œ ê°’ë§Œ ì¶”ì¶œ
{"question": itemgetter("question")}
# ê²°ê³¼: {"question": "actual question"}
```

## ğŸ“š Summary

### Key Takeaways

1. **`dumps`/`loads`**: Document ê°ì²´ì˜ ì§ë ¬í™”/ì—­ì§ë ¬í™”ë¡œ ì¤‘ë³µ ì œê±°ì™€ ì €ì¥ì— í•„ìˆ˜
2. **`RunnablePassthrough`**: ë‹¨ìˆœí•œ íŒŒì´í”„ë¼ì¸ì—ì„œ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬
3. **`itemgetter`**: ë³µì¡í•œ ë”•ì…”ë„ˆë¦¬ êµ¬ì¡°ì—ì„œ ê°’ ì¶”ì¶œ, LangChain í‘œì¤€ íŒ¨í„´

### ì„ íƒ ê°€ì´ë“œ

```python
# ë‹¨ìˆœí•œ êµ¬ì¡° â†’ RunnablePassthrough
chain.invoke("ë¬¸ìì—´")

# ë³µì¡í•œ êµ¬ì¡° â†’ itemgetter  
chain.invoke({"key": "value"})

# ì¤‘ë³µ ì œê±° â†’ dumps/loads
unique_docs = get_unique_union(document_lists)
```

### ì¼ë°˜ì ì¸ ì‹¤ìˆ˜

1. **RunnablePassthroughë¥¼ ë”•ì…”ë„ˆë¦¬ êµ¬ì¡°ì—ì„œ ì‚¬ìš©**
2. **Document ê°ì²´ë¥¼ ì§ì ‘ ë¹„êµ**
3. **itemgetter ëŒ€ì‹  ë³µì¡í•œ lambda ì‚¬ìš©**

ì´ ì»´í¬ë„ŒíŠ¸ë“¤ì„ ì˜¬ë°”ë¥´ê²Œ ì´í•´í•˜ê³  ì‚¬ìš©í•˜ë©´ íš¨ìœ¨ì ì´ê³  ì•ˆì •ì ì¸ RAG ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 