from dotenv import load_dotenv
import os
from langchain_openai import ChatOpenAI
from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field, model_validator
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.utils.function_calling import tool_example_to_messages

# Load environment variables
load_dotenv()

## Define the schema for the data extraction
class Person(BaseModel):
    """Information about a person extracted from text."""
    
    # Each field is optional to allow the model to decline extraction if unsure
    name: Optional[str] = Field(
        default=None, 
        description="The full name of the person"
    )
    age: Optional[int] = Field(
        default=None,
        description="The age of the person in years"
    )
    occupation: Optional[str] = Field(
        default=None,
        description="The job or profession of the person"
    )
    location: Optional[str] = Field(
        default=None,
        description="The city, country, or location where the person lives"
    )

class Company(BaseModel):
    """Information about a company extracted from text."""
    
    name: Optional[str] = Field(
        default=None,
        description="The name of the company"
    )
    industry: Optional[str] = Field(
        default=None,
        description="The industry or sector the company operates in"
    )
    location: Optional[str] = Field(
        default=None,
        description="The location of the company headquarters"
    )
    founded_year: Optional[int] = Field(
        default=None,
        description="The year the company was founded"
    )

class ExtractedData(BaseModel):
    """Container for all extracted structured data."""
    
    people: List[Person] = Field(
        default_factory=list,
        description="List of people mentioned in the text"
    )
    companies: List[Company] = Field(
        default_factory=list,
        description="List of companies mentioned in the text"
    )
    summary: Optional[str] = Field(
        default=None,
        description="A brief summary of the main topics discussed in the text"
    )
    
    @classmethod
    @model_validator(mode='before')
    def validate_lists(cls, data):
        """Validate and clean the input data.
        
        This validator ensures that None values are converted to empty lists
        for people and companies fields to prevent validation errors.
        """
        if isinstance(data, dict):
            # Convert None to empty list for people and companies
            if data.get('people') is None:
                data['people'] = []
            if data.get('companies') is None:
                data['companies'] = []
        return data

## Define the extraction chain
class ExtractionChain:
    """LangChain-based extraction chain for structured data extraction."""
    
    def __init__(self, model_name: str = "gpt-4o-mini", temperature: float = 0.1):
        """Initialize the extraction chain.
        
        Args:
            model_name: Name of the LLM model to use
            temperature: Temperature parameter for the model (0.0 for deterministic)
        """
        self.model_name = model_name
        self.temperature = temperature
        self.llm = None
        self.extraction_runnable = None
        
        # Initialize the model and chain
        self._setup_model()
        self._setup_extraction_chain()
        
    def _setup_model(self):
        """Set up the LLM model for extraction.
        
        This method initializes the chat model with structured output support.
        Currently supports OpenAI models but can be extended for other providers.
        """
        # Check if OpenAI API key is available
        if not os.getenv("OPENAI_API_KEY"):
            raise ValueError("OPENAI_API_KEY not found in environment variables")
            
        self.llm = ChatOpenAI(
            model=self.model_name,
            temperature=self.temperature
        )

    def _setup_extraction_chain(self):
        """Set up the extraction chain with prompt template.
        
        This method creates the complete extraction pipeline including
        the prompt template with Korean language support and example placeholders.
        """
        prompt_template = ChatPromptTemplate.from_messages([
            (
                "system",
                """You are an expert extraction algorithm that can extract structured information from unstructured text.
                
                Instructions:
                - Extract relevant information from the text accurately
                - If you don't know the value of an attribute, return null
                - Support both Korean and English text input
                - Be precise and don't make up information
                - For Korean names, preserve the original Korean characters
                
                í•œêµ­ì–´ ì§€ì›:
                - í•œêµ­ì–´ í…ìŠ¤íŠ¸ì—ì„œ ì •ë³´ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ì„¸ìš”
                - í•œêµ­ì–´ ì´ë¦„ì€ ì›ë³¸ í•œê¸€ì„ ìœ ì§€í•˜ì„¸ìš”
                - í™•ì‹¤í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” nullë¡œ ë°˜í™˜í•˜ì„¸ìš”
                """
            ),
            # Placeholder for few-shot examples
            MessagesPlaceholder("examples"),
            (
                "human", 
                "Extract structured information from the following text:\n\n{text}"
            ),
        ])
        
        # Create the extraction runnable with structured output
        self.extraction_runnable = prompt_template | self.llm.with_structured_output(
            schema=ExtractedData,
            method="function_calling",
            include_raw=False,
        )
        
    def _get_reference_examples(self) -> List[Dict[str, Any]]:
        """Get reference examples for few-shot learning.
        
        Returns:
            List of example dictionaries with input text and expected output
            
        This method provides reference examples to improve extraction accuracy.
        Examples include both Korean and English text with various entity types.
        """
        examples = [
            # Example 1: No entities found
            (
                "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”. í•˜ëŠ˜ì´ íŒŒë—ê³  êµ¬ë¦„ì´ í•˜ì–—ìŠµë‹ˆë‹¤.",
                ExtractedData(
                    people=[],
                    companies=[],
                    summary="Weather description - clear sky with white clouds"
                )
            ),
            # Example 2: Person extraction
            (
                "ê¹€ë¯¼ìˆ˜ëŠ” 35ì„¸ì˜ ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´ë¡œ ì„œìš¸ì—ì„œ ì¼í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
                ExtractedData(
                    people=[Person(
                        name="ê¹€ë¯¼ìˆ˜",
                        age=35,
                        occupation="ì†Œí”„íŠ¸ì›¨ì–´ ì—”ì§€ë‹ˆì–´",
                        location="ì„œìš¸"
                    )],
                    companies=[],
                    summary="Information about Kim Min-su, a software engineer from Seoul"
                )
            ),
            # Example 3: Company extraction
            (
                "ì‚¼ì„±ì „ìëŠ” 1969ë…„ì— ì„¤ë¦½ëœ ëŒ€í•œë¯¼êµ­ì˜ ëŒ€í‘œì ì¸ IT ê¸°ì—…ì…ë‹ˆë‹¤.",
                ExtractedData(
                    people=[],
                    companies=[Company(
                        name="ì‚¼ì„±ì „ì",
                        industry="IT",
                        location="ëŒ€í•œë¯¼êµ­",
                        founded_year=1969
                    )],
                    summary="Information about Samsung Electronics, a major Korean IT company"
                )
            ),
            # Example 4: Mixed content
            (
                "Steve Jobs founded Apple Inc. in 1976. He was a visionary leader in the technology industry.",
                ExtractedData(
                    people=[Person(
                        name="Steve Jobs",
                        age=None,
                        occupation="visionary leader",
                        location=None
                    )],
                    companies=[Company(
                        name="Apple Inc.",
                        industry="technology",
                        location=None,
                        founded_year=1976
                    )],
                    summary="Information about Steve Jobs and Apple Inc. founding"
                )
            )
        ]
        
        return examples
        
    def _convert_examples_to_messages(self, examples: List[tuple]) -> List:
        """Convert examples to message format for the model.
        
        Args:
            examples: List of (input_text, expected_output) tuples
            
        Returns:
            List of messages in the format expected by the model
        """
        messages = []
        
        for text, expected_output in examples:
            # Convert each example to the message format using LangChain utility
            # Based on LangChain documentation: tool_example_to_messages(input_text, tool_calls, ai_response=None)
            if expected_output.people or expected_output.companies:
                ai_response = "Detected entities."
            else:
                ai_response = "No entities detected."
                
            example_messages = tool_example_to_messages(
                text, 
                [expected_output], 
                ai_response=ai_response
            )
            messages.extend(example_messages)
            
        return messages
        
    def extract(self, text: str, use_examples: bool = True) -> ExtractedData:
        """Extract structured data from unstructured text.
        
        Args:
            text: Input text to extract information from
            use_examples: Whether to use few-shot examples for better performance
            
        Returns:
            ExtractedData object containing extracted information
            
        This method performs the actual extraction using the configured model
        and prompt template. It supports both Korean and English text input.
        """
        if not self.extraction_runnable:
            raise ValueError("Extraction chain not properly initialized")
            
        # Prepare examples if requested
        examples = []
        if use_examples:
            reference_examples = self._get_reference_examples()
            examples = self._convert_examples_to_messages(reference_examples)
            
        # Run extraction
        try:
            result = self.extraction_runnable.invoke({
                "text": text,
                "examples": examples
            })
            return result
            
        except Exception as e:
            raise Exception(f"Extraction failed: {str(e)}")
            
    def batch_extract(self, texts: List[str], use_examples: bool = True) -> List[ExtractedData]:
        """Extract structured data from multiple texts.
        
        Args:
            texts: List of input texts to extract information from
            use_examples: Whether to use few-shot examples for better performance
            
        Returns:
            List of ExtractedData objects containing extracted information
        """
        results = []
        for text in texts:
            result = self.extract(text, use_examples=use_examples)
            results.append(result)
        return results

def main():
    """Main function to demonstrate the extraction functionality.
    
    This function demonstrates how to use the ExtractionChain class
    with various Korean and English text examples. It shows both
    single extraction and batch extraction capabilities.
    """
    
    print("=== LangChain ë°ì´í„° ì¶”ì¶œ ì˜ˆì œ ===")
    print("=== LangChain Data Extraction Example ===\n")
    
    try:
        # Initialize extraction chain
        print("ğŸ“‹ ì¶”ì¶œ ì²´ì¸ ì´ˆê¸°í™” ì¤‘...")
        extractor = ExtractionChain()
        print("âœ… ì¶”ì¶œ ì²´ì¸ ì´ˆê¸°í™” ì™„ë£Œ!\n")
        
        # Test examples in Korean and English
        test_texts = [
            # Korean examples
            "ë°•ì§€ì„±ì€ 42ì„¸ì˜ ì „ ì¶•êµ¬ì„ ìˆ˜ë¡œ í˜„ì¬ ì„œìš¸ì—ì„œ ì¶•êµ¬ í•´ì„¤ê°€ë¡œ í™œë™í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŠ” ë§¨ì²´ìŠ¤í„° ìœ ë‚˜ì´í‹°ë“œì—ì„œ í™œì•½í–ˆë˜ í•œêµ­ì˜ ëŒ€í‘œì ì¸ ì¶•êµ¬ì„ ìˆ˜ì…ë‹ˆë‹¤.",
            
            "ë„¤ì´ë²„ëŠ” 1999ë…„ì— ì„¤ë¦½ëœ ëŒ€í•œë¯¼êµ­ì˜ ëŒ€í‘œì ì¸ ì¸í„°ë„· ê¸°ì—…ìœ¼ë¡œ ê²€ìƒ‰ì—”ì§„ê³¼ ì˜¨ë¼ì¸ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ë³¸ì‚¬ëŠ” ê²½ê¸°ë„ ë¶„ë‹¹ì— ìœ„ì¹˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
            
            "ì´ì¬ìš© ì‚¼ì„±ì „ì ë¶€íšŒì¥ì€ ê¸°ìˆ  í˜ì‹ ì„ í†µí•´ íšŒì‚¬ë¥¼ ì´ëŒê³  ìˆìŠµë‹ˆë‹¤. ì‚¼ì„±ì „ìëŠ” ë°˜ë„ì²´ ì‚°ì—…ì—ì„œ ì„¸ê³„ì ì¸ ê¸°ì—…ìœ¼ë¡œ ì„±ì¥í–ˆìŠµë‹ˆë‹¤.",
            
            # English examples
            "Elon Musk, the 52-year-old entrepreneur, is the CEO of Tesla and SpaceX. He's known for his innovative approach to electric vehicles and space exploration.",
            
            "Microsoft was founded in 1975 by Bill Gates and Paul Allen. The company is headquartered in Redmond, Washington, and is a leader in software and cloud computing.",
            
            # Mixed content
            "Appleì˜ CEOì¸ Tim Cookì€ 2011ë…„ë¶€í„° íšŒì‚¬ë¥¼ ì´ëŒê³  ìˆìŠµë‹ˆë‹¤. Apple Inc.ëŠ” 1976ë…„ì— ì„¤ë¦½ë˜ì—ˆìœ¼ë©° í˜ì‹ ì ì¸ ê¸°ìˆ  ì œí’ˆìœ¼ë¡œ ìœ ëª…í•©ë‹ˆë‹¤.",
            
            # No entities
            "ì˜¤ëŠ˜ì€ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ìŠµë‹ˆë‹¤. íŒŒë€ í•˜ëŠ˜ê³¼ ë”°ëœ»í•œ í–‡ì‚´ì´ ê¸°ë¶„ì„ ì¢‹ê²Œ ë§Œë“­ë‹ˆë‹¤."
        ]
        
        print("ğŸ” ê°œë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ í…ŒìŠ¤íŠ¸:")
        print("=" * 50)
        
        for i, text in enumerate(test_texts, 1):
            print(f"\nğŸ“„ í…ŒìŠ¤íŠ¸ {i}: {text[:50]}...")
            
            # Extract with examples
            result = extractor.extract(text, use_examples=True)
            
            # Display results
            print("ğŸ“Š ì¶”ì¶œ ê²°ê³¼:")
            if result.people:
                print(f"  ğŸ‘¤ ì¸ë¬¼: {len(result.people)}ëª…")
                for person in result.people:
                    print(f"    - {person.name} ({person.age}ì„¸, {person.occupation}, {person.location})")
            
            if result.companies:
                print(f"  ğŸ¢ íšŒì‚¬: {len(result.companies)}ê°œ")
                for company in result.companies:
                    print(f"    - {company.name} ({company.industry}, {company.location}, {company.founded_year})")
            
            if result.summary:
                print(f"  ğŸ“ ìš”ì•½: {result.summary}")
            
            if not result.people and not result.companies:
                print("  âŒ ì¶”ì¶œëœ ì—”í‹°í‹°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
        print(f"\n{'='*50}")
        print("ğŸš€ ë°°ì¹˜ ì¶”ì¶œ í…ŒìŠ¤íŠ¸:")
        
        # Test batch extraction
        batch_results = extractor.batch_extract(test_texts[:3], use_examples=True)
        
        print(f"ğŸ“Š ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼: {len(batch_results)}ê°œ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì™„ë£Œ")
        
        total_people = sum(len(result.people) for result in batch_results)
        total_companies = sum(len(result.companies) for result in batch_results)
        
        print(f"  ğŸ‘¥ ì´ ì¸ë¬¼: {total_people}ëª…")
        print(f"  ğŸ¢ ì´ íšŒì‚¬: {total_companies}ê°œ")
        
        print(f"\n{'='*50}")
        print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
        print("1. OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
        print("2. í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”:")
        print("   pip install langchain-openai python-dotenv")
        print("3. .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”")

def test_extraction_without_examples():
    """Test extraction performance without reference examples.
    
    This function demonstrates the difference in extraction quality
    when using the model without few-shot examples vs. with examples.
    """
    
    print("ğŸ”¬ ì°¸ì¡° ì˜ˆì‹œ ì—†ì´ ì¶”ì¶œ í…ŒìŠ¤íŠ¸:")
    print("=" * 40)
    
    try:
        extractor = ExtractionChain()
        
        test_text = "ê¹€ì² ìˆ˜ëŠ” 30ì„¸ì˜ ê°œë°œìë¡œ ë¶€ì‚°ì—ì„œ ì¼í•˜ê³  ìˆìŠµë‹ˆë‹¤."
        
        # Without examples
        result_no_examples = extractor.extract(test_text, use_examples=False)
        print("âŒ ì˜ˆì‹œ ì—†ìŒ:")
        print(f"   ì¸ë¬¼: {len(result_no_examples.people)}ëª…")
        
        # With examples
        result_with_examples = extractor.extract(test_text, use_examples=True)
        print("âœ… ì˜ˆì‹œ í¬í•¨:")
        print(f"   ì¸ë¬¼: {len(result_with_examples.people)}ëª…")
        
    except Exception as e:
        print(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")

if __name__ == "__main__":
    """Entry point for the extraction demo.
    
    This script demonstrates the complete extraction functionality
    including both Korean and English text processing.
    """
    
    # Run main demonstration
    main()
    
    # Optional: Test without examples
    print("\n" + "="*60)
    test_extraction_without_examples()